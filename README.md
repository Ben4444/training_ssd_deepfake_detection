# Training a Single Shot MultiBox Detector (SSD) deep learning model for deepfake detection
This is code I used - some original, some adapted from other GitHub repositories (and appropriately credited) - to train an SSD300 model to discriminate between real and manipulated faces in images extracted from original and deepfaked videos.

The `data_management` subfolder features R code I used to get all my annotations and images in order, so they were ready to be fed into the SSD model. Files that are in the subfolder include:
* `video_annotations_data_management.R` - Imports the three annotation JSON files that were exported from the Clay Sciences annotation platform (not included in the `data_management` subfolder because they are very large files), reformats the data into a nice data frame, cleans the annotations, creates resized bounding box coordinates, and exports the clean annotations dataset as an RDS file.
* `annotations.Rds` - The clean annotations dataset.
* `dataset_prep.R` - Imports the clean annotations dataset, formats the data to match specific SSD300 requirements, splits the dataset up into training, validation, and test datasets and exports them as CSV files, and calculates the per-color channel average of all the images in the dataset.
* `csv_files.zip` - Contains all the CSV files of the annotated datasets - training, validation, test, practice training and practice validation datasets.
* `all_videos.zip` - Contains a limited set of images, taken from the full dataset. The limited set of images correspond to the images from practice_video_fake1 and practice_video_fake2. These are also the images represented in the practice training and practice validation CSV files. The images contained in this file (and all images in the full dataset) were obtained by slicing videos into frames via FFmpeg.

The `analysis` subfolder features Jupyter notebooks and programs coded in Python for running an SSD model using the TensorFlow backend for Keras. Almost all code in this subfolder was downloaded from the repository [ssd_keras](https://github.com/pierluigiferrari/ssd_keras) by Pierluigi Ferrari. The Python programs that are called from the Jupyter notebooks are all untouched and come straight from Pierluigi Ferrari. The Jupyter notebooks are based on code downloaded from the [ssd_keras](https://github.com/pierluigiferrari/ssd_keras) repository, but have been modified by me to fit the specifications of my dataset. The analysis was run using Google Cloud Platform's [AI Platform Notebooks](https://cloud.google.com/ai-platform-notebooks) on a NVIDIA Tesla K80 GPU. Files that are in the subfolder include:
* `install.ipynb` - Installs Python modules into the AI Platform Notebooks environment that were not pre-installed by Google. I used the TensorFlow 1.15 environment as a base. Some module versions also had to be changed from those that were pre-installed so they would be compatible with the SSD code. Also features a small code snippet to verify that the AI Platform Notebooks environment is able to run GPUs.
* `ssd300_training.ipynb` - Trains an SSD300 model from scratch, with many options available. This code allows one to train everything up all at once or train the model piecewise through established checkpoints. Some of the other options that can be customized are the optimizer used, schedule of the learning rate, and length of training. The notebook code came originally from Pierluigi Ferrari but was modified by me to fit the specifications of my data. This notebook calls in many of the other Python programs written by Pierluigi Ferrari to run "under the hood".
* `ssd300_evaluation.ipynb` - Evaluates an SSD300 model version after a specific epoch. Evaluation is assessed through the creation of precision-recall curves and the calculation of the average precision for each class, and calculation of the mAP. The evaluation can be run using the pre-2010 or post-2010 PASCAL VOC algorithms, and there are many more options available. The notebook code came originally from Pierluigi Ferrari but was modified by me to fit the specifications of my data. This notebook calls in many of the other Python programs written by Pierluigi Ferrari to run "under the hood".
* `ssd300_inference.ipynb` - Runs predictions on provided images using an SSD300 model version after a specific epoch. Predictions can be made on images with or without ground truth annotations. A number of options are available, including setting the confidence threshold at which predictions are made. The notebook code came originally from Pierluigi Ferrari but was modified by me to fit the specifications of my data. This notebook calls in many of the other Python programs written by Pierluigi Ferrari to run "under the hood".
* `bounding_box_utils` - Python utility program that is called during SSD training, evaluation, or inference. Program was written by Pierluigi Ferrari.
* `data_generator` - Python programs to assemble datasets that are used during SSD training, evaluation, or inference. All programs were written by Pierluigi Ferrari.
* `eval_utils` - Python utility programs that are called during SSD evaluation. All programs were written by Pierluigi Ferrari.
* `keras_layers` - Python programs that define SSD model layers to be used during SSD training, evaluation, or inference. All programs were written by Pierluigi Ferrari.
* `keras_loss_function` - Python program that defines the SSD model loss to be used during SSD training, evaluation, or inference. Program was written by Pierluigi Ferrari.
* `misc_utils` - Python utility program that is called during SSD training, evaluation, or inference. Program was written by Pierluigi Ferrari.
* `models` - Python programs of the SSD models. There is code available for the SSD300, SSD512, and SSD7. All programs were written by Pierluigi Ferrari.
* `ssd_encoder_decoder` - Python programs that are called during SSD training, evaluation, or inference to encode/decode predicted bounding boxes. All programs were written by Pierluigi Ferrari.

The `results` subfolder features evaluation and prediction results for the SSD300 model trained to detect real and deepfake faces in images extracted from videos. Folders that are in the subfolder include:
* `Evaluation` - Evaluation results for each of the 15 trained epochs. Model performance was assessed through the creation of precision-recall curves and the calculation of the average precision per class.
* `Prediction` - Predictions made on images with and without ground truth annotations using the best performing SSD model version, epoch 8. In the predictions made on images with ground truth annotations, the green bounding box is the ground truth.
